from typing import Any

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from torch.utils.data import DataLoader, Dataset
from Utils.preferences import Preferences


class DutchDataset(Dataset):
    def __init__(self, x: np.ndarray, z: np.ndarray, y: np.ndarray) -> None:
        """
        Initializes the DutchDataset with features, sensitive attributes, and targets.

        Stores samples, sensitive features, targets, and indexes for dataset access.

        Args:
            x (np.ndarray): Feature data array.
            z (np.ndarray): Sensitive attribute data array.
            y (np.ndarray): Target data array.

        Returns:
            None
        """
        self.samples = x
        self.sensitive_features = z
        self.targets = y
        self.indexes = range(len(self.samples))

    def __len__(self) -> int:
        """
        Returns the number of samples in the dataset.

        Args:
            None

        Returns:
            int: Size of the dataset.
        """
        return len(self.samples)

    def __getitem__(self, idx: int) -> tuple[Any, Any, Any]:
        """
        Retrieves a single sample from the dataset by index.

        Returns feature, sensitive attribute, and target for the given index.

        Args:
            idx (int): Index of the sample to retrieve.

        Returns:
            tuple[Any, Any, Any]: (feature sample, sensitive sample, target sample)
        """
        x_sample = self.samples[idx]
        z_sample = self.sensitive_features[idx]
        y_sample = self.targets[idx]

        return x_sample, z_sample, y_sample


def get_dutch_scaler(
    sweep: bool,
    seed: int,
    dutch_df: pd.DataFrame | None = None,
    validation_seed: int | None = None,
) -> MinMaxScaler:
    """
    Computes and returns a MinMaxScaler fitted on the Dutch dataset.

    Validates input DataFrame and uses prepare_dutch to obtain the scaler.

    Args:
        sweep (bool): Whether in hyperparameter sweep mode.
        seed (int): Random seed for reproducibility.
        dutch_df (pd.DataFrame | None): Dutch data DataFrame; required.
        validation_seed (int | None): Seed for validation split.

    Returns:
        MinMaxScaler: Fitted scaler instance.

    Raises:
        ValueError: If dutch_df is None.
    """
    if dutch_df is None:
        raise ValueError("dutch_df cannot be None")

    _, _, _, scaler = prepare_dutch(
        dutch_df=dutch_df,
    )
    return scaler


def prepare_dutch(
    dutch_df: pd.DataFrame,
    scaler: MinMaxScaler | None = None,
) -> tuple[np.ndarray, np.ndarray, np.ndarray, MinMaxScaler]:
    """
    Preprocesses Dutch DataFrame: handles missing values, binarizes sex/occupation, one-hot encodes categoricals, scales features.

    Fills missing values with mode, creates binary targets/sensitive, applies MinMaxScaler if not provided.

    Args:
        dutch_df (pd.DataFrame): Input Dutch data.
        scaler (MinMaxScaler | None): Pre-fitted scaler; if None, fits a new one.

    Returns:
        tuple[np.ndarray, np.ndarray, np.ndarray, MinMaxScaler]: Scaled features, sensitive array, target array, scaler.

    Raises:
        ValueError: If missing values persist after filling.
    """
    # check the columns with missign values:
    missing_values_columns = dutch_df.columns[dutch_df.isna().any()].tolist()
    for column in missing_values_columns:
        dutch_df[column] = dutch_df[column].fillna(dutch_df[column].mode()[0])

    if len(dutch_df.columns[dutch_df.isna().any()].tolist()) != 0:
        error_message = "There are still missing values in the dataset"
        raise ValueError(error_message)

    dutch_df["sex_binary"] = np.where(dutch_df["sex"] == 1, 1, 0)
    dutch_df["occupation_binary"] = np.where(dutch_df["occupation"] >= 300, 1, 0)

    del dutch_df["sex"]
    del dutch_df["occupation"]

    y_train = dutch_df["occupation_binary"].astype(int).values
    z_train = dutch_df["sex_binary"].astype(int).values
    del dutch_df["occupation_binary"]
    dutch_df = pd.get_dummies(dutch_df, columns=None, drop_first=False)

    if scaler is None:
        scaler = MinMaxScaler()
    x_train = scaler.fit_transform(dutch_df)

    return x_train, np.array(z_train), np.array(y_train), scaler


def prepare_dutch_for_cross_silo(preferences: Preferences, partition: Any, partition_id: int) -> Any:
    """
    Prepares Dutch data for cross-silo federated learning from a partition.

    Splits into train/test (20% test), optionally train/val for sweep; processes with prepare_dutch, creates DataLoaders and FlowerClient. Prints debug info for partition_id 0/1.

    Args:
        preferences (Preferences): FL configuration including batch_size, seed, scaler.
        partition (Any): Data partition for this client.
        partition_id (int): Client ID for debug printing.

    Returns:
        Any: FlowerClient instance wrapped as .to_client().

    Raises:
        ValueError: If data processing fails.
    """
    if preferences.setting == "training":
        from Client.client import FlowerClient
    else:
        from Client.evaluation_client import FlowerClient

    partition_train_test = partition.train_test_split(test_size=0.2, seed=preferences.seed)

    test = partition_train_test["test"]
    if partition_id == 0:
        print(f"partition Id {partition_id} - Test set size: {len(test)}")
        print(f"Test set columns: {test.column_names}")
        print(f"Test set example:\n{test[0]}")
    elif partition_id == 1:
        print(f"partition Id {partition_id} - Test set size: {len(test)}")
        print(f"Test set columns: {test.column_names}")
        print(f"Test set example:\n{test[0]}")

    if preferences.sweep:
        print("[Preparing data for cross-silo for sweep...]")

        partition_loader_train_val = partition_train_test["train"].train_test_split(
            test_size=0.2, seed=preferences.node_shuffle_seed
        )
        train = partition_loader_train_val["train"].to_pandas()
        val = partition_loader_train_val["test"].to_pandas()

        x_train, z_train, y_train, _ = prepare_dutch(
            dutch_df=train,
            scaler=preferences.scaler,
        )

        x_val, z_val, y_val, _ = prepare_dutch(
            dutch_df=val,
            scaler=preferences.scaler,
        )

        train_dataset = DutchDataset(
            x=np.hstack((x_train, np.ones((x_train.shape[0], 1)))).astype(np.float32),
            z=z_train.astype(np.float32),
            y=y_train.astype(np.float32),
        )
        val_dataset = DutchDataset(
            x=np.hstack((x_val, np.ones((x_val.shape[0], 1)))).astype(np.float32),
            z=z_val.astype(np.float32),
            y=y_val.astype(np.float32),
        )

        trainloader = DataLoader(train_dataset, batch_size=preferences.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=preferences.batch_size, shuffle=False)


        return FlowerClient(
            trainloader=trainloader, valloader=val_loader, preferences=preferences, partition_id=partition_id
        ).to_client()
    print("[Preparing data for cross-silo...]")
    train = partition_train_test["train"].to_pandas()
    test = partition_train_test["test"].to_pandas()

    x_train, z_train, y_train, _ = prepare_dutch(
        dutch_df=train,
        scaler=preferences.scaler,
    )

    x_test, z_test, y_test, _ = prepare_dutch(
        dutch_df=test,
        scaler=preferences.scaler,
    )

    train_dataset = DutchDataset(
        x=np.hstack((x_train, np.ones((x_train.shape[0], 1)))).astype(np.float32),
        z=z_train.astype(np.float32),
        y=y_train.astype(np.float32),
    )
    test_dataset = DutchDataset(
        x=np.hstack((x_test, np.ones((x_test.shape[0], 1)))).astype(np.float32),
        z=z_test.astype(np.float32),
        y=y_test.astype(np.float32),
    )

    print("Train dataset size:", len(train_dataset))
    print("Test dataset size:", len(test_dataset))

    trainloader = DataLoader(train_dataset, batch_size=preferences.batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=preferences.batch_size, shuffle=False)

    return FlowerClient(
        trainloader=trainloader, valloader=test_loader, preferences=preferences, partition_id=partition_id
    ).to_client()
